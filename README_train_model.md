
# ğŸ“˜ GuÃ­a de EjecuciÃ³n â€” `train_model.py`

Este documento explica paso a paso cÃ³mo ejecutar el script **`train_model.py`**, cuyo objetivo es entrenar y comparar dos modelos de regresiÃ³n para el TP Properati:

- **LinearRegression**
- **RandomForestRegressor**

El script tambiÃ©n guarda predicciones y mÃ©tricas en la base SQLite.

---

## âœ… 1. Requisitos previos

Antes de ejecutar el entrenamiento, asegurate de tener listos los siguientes elementos:

### ğŸ“Œ Archivos necesarios dentro de `data/artifacts/`

| Archivo | Generado por | Â¿Para quÃ© sirve? |
|--------|--------------|------------------|
| `X_preprocessed.npz` o `.npy` | preprocessing.py | Matriz de features lista para modelado |
| `y.npy` | preprocessing.py | Vector objetivo (precio) |
| `database.db` | load_to_sqlite.py | Base donde se guardarÃ¡n mÃ©tricas y predicciones |
| `feature_names.json` | preprocessing.py | Nombres de columnas transformadas |

Ejemplo de estructura esperada:

```
tppa/
 â”œâ”€ Scripts/
 â”‚   â””â”€ train_model.py
 â”œâ”€ data/
 â”‚   â””â”€ artifacts/
 â”‚       â”œâ”€ X_preprocessed.npz
 â”‚       â”œâ”€ y.npy
 â”‚       â”œâ”€ database.db
 â”‚       â””â”€ feature_names.json
```

---

## âœ… 2. Activar entorno virtual

En PowerShell, desde la raÃ­z del proyecto:

```powershell
.	ppa\Scripts\Activate.ps1
```

---

## âœ… 3. Ejecutar el script

Desde la raÃ­z del proyecto:

```powershell
python .\Scripts\train_model.py --db_path .\data\artifacts\database.db --artifacts_dir .\data\artifacts --max_samples 20000
```

### ğŸ“Œ ParÃ¡metros disponibles

| ParÃ¡metro | DescripciÃ³n | Default |
|----------|-------------|---------|
| `--db_path` | Ruta a `database.db` | `data/artifacts/database.db` |
| `--artifacts_dir` | Carpeta donde viven X e y | `data/artifacts` |
| `--test_size` | ProporciÃ³n para test | `0.2` |
| `--max_samples` | Filas mÃ¡ximas a usar para evitar problemas de RAM | `150000` |
| `--random_state` | Semilla | `42` |

Ejemplo con parÃ¡metros personalizados:

```powershell
python .\Scripts	rain_model.py --test_size 0.25 --max_samples 100000
```

---

## âœ… 4. Â¿QuÃ© ocurre durante la ejecuciÃ³n?

El script:

1. **Carga X e y desde `data/artifacts/`.**
2. **Submuestrea** (si X es muy grande) para manejar memoria.
3. Realiza `train_test_split`.
4. Entrena:
   - LinearRegression  
   - RandomForestRegressor
5. Calcula:
   - RMSE  
   - MAE  
   - RÂ²  
6. Inserta resultados en **SQLite**:

### Tablas creadas/llenadas

| Tabla | Contenido |
|-------|-----------|
| `model_results` | Predicciones del **set de test**, por fila |
| `model_metrics` | MÃ©tricas por modelo y split (train/test) |

Ejemplo de registros en `model_metrics`:

| model_name | split | rmse | mae | r2 |
|------------|--------|------|------|------|
| LinearRegression | test | 82000 | 54000 | 0.62 |
| RandomForestRegressor | test | 69000 | 48000 | 0.71 |

---

## âœ… 5. CÃ³mo verificar los resultados

### Ver mÃ©tricas en SQLite

AbrÃ­ DB Browser for SQLite â†’ `database.db` â†’ pestaÃ±a **Browse Data** â†’ tabla `model_metrics`.

Consulta SQL rÃ¡pida:

```sql
SELECT model_name, split, rmse, mae, r2
FROM model_metrics
ORDER BY split, rmse;
```

### Ver predicciones

```sql
SELECT *
FROM model_results
WHERE model_name = 'RandomForestRegressor'
LIMIT 20;
```

---

## ğŸ“Š 6. InterpretaciÃ³n esperada

Generalmente:

- **RandomForestRegressor** suele obtener mejores mÃ©tricas que LinearRegression.
- La comparaciÃ³n se basa en:
  - RMSE mÃ¡s bajo
  - MAE mÃ¡s bajo
  - RÂ² mÃ¡s alto

Esto cumple con el requerimiento del TP: **comparar al menos dos modelos de regresiÃ³n**.

---

## ğŸ‰ Â¡Listo!

Tu pipeline completo ahora incluye:

1. Preprocesamiento  
2. Carga en SQLite  
3. EDA  
4. Entrenamiento + comparaciÃ³n de modelos  
5. MÃ©tricas guardadas de forma reproducible  

Si querÃ©s, puedo generarte tambiÃ©n:

- Un **train_model_v2.py** con barra de progreso, logs o guardar el modelo entrenado.
- Un **script evaluate_model.py** para comparar modelos automÃ¡ticamente.
- Un **informe en DOCX** con grÃ¡ficos, tabla de mÃ©tricas y conclusiones.

Solo pedÃ­melo ğŸ™‚
